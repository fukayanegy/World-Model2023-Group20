{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfmtORdYMUTo"
      },
      "source": [
        "# 2023年 世界モデル 第7回演習\n",
        "\n",
        "本演習では，いわゆる世界モデルを用いた強化学習アルゴリズムである **RSSM (Recurrent State Space Model)**[[1]](#scrollTo=J_PCEOJ69prx) と**Dreamer**[[2]](#scrollTo=J_PCEOJ69prx)を実装します．\n",
        "\n",
        "## 目次\n",
        "\n",
        "1. [準備](#scrollTo=yDN8Ohc0Mh8C)\n",
        "2. [環境の設定](#scrollTo=_eayBK1HPV5H)\n",
        "3. [RSSM](#scrollTo=B3rWEGtkA3e_&line=1&uniqifier=1)\n",
        "4. [RSSMの実装](#scrollTo=xJfU7ygCMeJn)\n",
        "5. [補助機能の実装](#scrollTo=WhlVvU3aZ5FC)\n",
        "6. [Dreamerの実装](#scrollTo=keAW0J-qS24Q)\n",
        "7. [エージェントの実装](#scrollTo=GdKZ1S2_boOd)\n",
        "8. [ハイパーパラメータの設定と学習の準備](#scrollTo=QUPWAkpyc9Z-)\n",
        "9. [学習](#scrollTo=yUoI0l9Ee0Tp)\n",
        "10. [結果の確認](#scrollTo=E3F2tAU0kepm)\n",
        "11. [参考文献](##scrollTo=J_PCEOJ69prx&line=4&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDN8Ohc0Mh8C"
      },
      "source": [
        "## 1.準備\n",
        "まず，演習を行うために必要な準備を行います．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXOA_CGxNmTe"
      },
      "source": [
        "この演習では，環境として[PyBullet](https://github.com/bulletphysics/bullet3)を用います．PyBulletは`pip`を用いてインストールします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MY7wAYcA1Lii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "a8598b15-c2cc-46a7-94a6-4cadb82b2c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting setuptools==65.5.0\n",
            "  Downloading setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel<0.40.0\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: wheel, setuptools\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.41.3\n",
            "    Uninstalling wheel-0.41.3:\n",
            "      Successfully uninstalled wheel-0.41.3\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 65.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-65.5.0 wheel-0.38.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install setuptools==65.5.0 \"wheel<0.40.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FZaErbWsMOOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafcdd74-b989-4c50-df5f-798e658132e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.5.tar.gz (80.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym==0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.21.0) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.21.0) (2.2.1)\n",
            "Building wheels for collected packages: gym, pybullet\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616797 sha256=7e7fa5a270cef696c31c3a8ee4aa1b5414096da0a016a2b12ec30a17cb9207cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/aa/90/b67df76370d3916a2189b662cf48da38ce41a4e7e58b6abff5\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-3.2.5-cp310-cp310-linux_x86_64.whl size=99850562 sha256=d0b2ee95f2f1218b00ba33b689d4f9d724b4e88d506e74b72a26f12955f74e7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fa/1a/c315a5133f0c9bf202a6daa5d70891120e7fe403e06e3407cc\n",
            "Successfully built gym pybullet\n",
            "Installing collected packages: pybullet, gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.21.0 pybullet-3.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pybullet gym==0.21.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGdfCWjtN8t-"
      },
      "source": [
        "必要なライブラリをインポートします．今回使うライブラリは，PyBullet以外はColabでは最初から入っていますが，手元の環境で行う場合はこれらのライブラリも`pip`等で事前にインストールする必要があります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "72zXgw6dMZ3_"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import time\n",
        "from typing import Any, List, Tuple\n",
        "\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.distributions import Normal\n",
        "from torch.distributions.kl import kl_divergence\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# 可視化のためにTensorBoardを用いるので，Colab上でTensorBoardを表示するための宣言を行う\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pybullet_envs  # PyBulletの環境をgymに登録する"
      ],
      "metadata": {
        "id": "Mh6RRMCLpX3E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVXol8PNO74X"
      },
      "source": [
        "今回の学習にはGPUが必要です．\n",
        "\n",
        "以下のコードを実行して， 結果が'cuda'でなければ「ランタイム」 →　 「ランタイムのタイプを変更」でGPUモードに変更しましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SM8S09VFO2Y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a628c3-75ad-40a3-a493-57e7835cfe2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# torch.deviceを定義．この変数は後々モデルやデータをGPUに転送する時にも使います\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmOEoN-6PLkp"
      },
      "source": [
        "きちんとGPUが使える状態になっているかチェックしておきます． ColabのGPU割り当てにはランダム性があるので人によって結果が違う場合がありますが， どれでも実行には問題ありません（学習にかかる時間に幾らかの差は出ます）．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P2XwZ-e9O-KM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef02dba-d243-4ca3-ef12-fbcd27d420bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 23 15:28:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eayBK1HPV5H"
      },
      "source": [
        "## 2.環境の設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvrA4khsPelK"
      },
      "source": [
        "環境を扱いやすくするために，いくつかラッパーを挟みます．\n",
        "\n",
        "今回はPyBulletを画像入力の環境として用います．環境を作成して，画像がどのようになっているかを見てみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "byt7c-EYPQP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "59f1114e-f832-4a42-ba5d-6c6a154226fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"HalfCheetahBulletEnv-v0\")  # 環境を読み込む．\n",
        "env.reset()\n",
        "image = env.render(mode=\"rgb_array\")  # env.renderで画像を取得\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKaLnTipP98p"
      },
      "source": [
        "画像が無事表示されたでしょうか．\n",
        "\n",
        "中央に見える２本足の何かを前方に走らせるのが`HalfCheetah`のタスクです．\n",
        "\n",
        "上記画像ではカメラの位置が遠いので，カメラの位置と角度を調整するラッパーを作成します．\n",
        "\n",
        "また，同時に通常は低次元の状態を観測として用いる環境である`HalfCheetahBulletEnv-v0`を画像を観測として用いる環境として扱えるようにしておきます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KWcf0WHzPvw-"
      },
      "outputs": [],
      "source": [
        "class GymWrapper_PyBullet(object):\n",
        "    \"\"\"\n",
        "    PyBullet環境のためのラッパー\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"]}\n",
        "    reward_range = (-np.inf, np.inf)\n",
        "\n",
        "    # __init__でカメラ位置に関するパラメータ（ cam_dist:カメラ距離，cam_yaw：カメラの水平面での回転，cam_pitch:カメラの縦方向での回転）を受け取り，カメラの位置を調整できるようにします.\n",
        "    # 　同時に画像の大きさも変更できるようにします\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: gym.Env,\n",
        "        cam_dist: int = 3,\n",
        "        cam_yaw: int = 0,\n",
        "        cam_pitch: int = -30,\n",
        "        render_width: int = 320,\n",
        "        render_height: int = 240,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env : gym.Env\n",
        "            gymで提供されている環境のインスタンス．\n",
        "        cam_dist : int\n",
        "            カメラの距離．\n",
        "        cam_yaw : int\n",
        "            カメラの水平面での回転．\n",
        "        cam_pitch : int\n",
        "            カメラの縦方向での回転．\n",
        "        render_width : int\n",
        "            観測画像の幅．\n",
        "        render_height : int\n",
        "            観測画像の高さ．\n",
        "        \"\"\"\n",
        "        self._env = env\n",
        "        self._env.env._cam_dist = cam_dist\n",
        "        self._env.env._cam_yaw = cam_yaw\n",
        "        self._env.env._cam_pitch = cam_pitch\n",
        "        self._env.env._render_width = render_width\n",
        "        self._env.env._render_height = render_height\n",
        "\n",
        "    def __getattr(self, name: str) -> Any:\n",
        "        \"\"\"\n",
        "        環境が保持している属性値を取得するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        name : str\n",
        "            取得したい属性値の名前．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        _env.name : Any\n",
        "            環境が保持している属性値．\n",
        "        \"\"\"\n",
        "        return getattr(self._env, name)\n",
        "\n",
        "    @property\n",
        "    def observation_space(self) -> gym.spaces.Box:\n",
        "        \"\"\"\n",
        "        観測空間に関する情報を取得するメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        space : gym.spaces.Box\n",
        "            観測空間に関する情報（各画素値の最小値，各画素値の最大値，観測データの形状， データの型）．\n",
        "        \"\"\"\n",
        "        width = self._env.env._render_width\n",
        "        height = self._env.env._render_height\n",
        "        return gym.spaces.Box(0, 255, (height, width, 3), dtype=np.uint8)\n",
        "\n",
        "    @property\n",
        "    def action_space(self) -> gym.spaces.Box:\n",
        "        \"\"\"\n",
        "        行動空間に関する情報を取得するメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        space : gym.spaces.Box\n",
        "            行動空間に関する情報（各行動の最小値，各行動の最大値，行動空間の次元， データの型） ．\n",
        "        \"\"\"\n",
        "        return self._env.action_space\n",
        "\n",
        "    # 　元の観測（低次元の状態）は今回は捨てて，env.render()で取得した画像を観測とします.\n",
        "    #  画像，報酬，終了シグナルが得られます.\n",
        "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):\n",
        "        \"\"\"\n",
        "        環境に行動を与え次の観測，報酬，終了フラグを取得するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        action : np.dnarray (action_dim, )\n",
        "            与える行動．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (height, width, 3)\n",
        "            行動を与えたときの次の観測．\n",
        "        reward : float\n",
        "            行動を与えたときに得られる報酬．\n",
        "        done : bool\n",
        "            エピソードが終了したかどうか表すフラグ．\n",
        "        info : dict\n",
        "            その他の環境に関する情報．\n",
        "        \"\"\"\n",
        "        _, reward, done, info = self._env.step(action)\n",
        "        obs = self._env.render(mode=\"rgb_array\")\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        環境をリセットするためのメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (height, width, 3)\n",
        "            環境をリセットしたときの初期の観測．\n",
        "        \"\"\"\n",
        "        self._env.reset()\n",
        "        obs = self._env.render(mode=\"rgb_array\")\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode=\"human\", **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        観測をレンダリングするためのメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode : str\n",
        "            レンダリング方法に関するオプション． (default='human')\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (height, width, 3)\n",
        "            観測をレンダリングした結果．\n",
        "        \"\"\"\n",
        "        return self._env.render(mode, **kwargs)\n",
        "\n",
        "    def close(self) -> None:\n",
        "        \"\"\"\n",
        "        環境を閉じるためのメソッド．\n",
        "        \"\"\"\n",
        "        self._env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Bc5PvTQ_05"
      },
      "source": [
        "環境にラッパーを適用します．同時にカメラ位置に関するパラメータを与えて，カメラの位置と角度を調整します．（今回カメラのパラメータは人力で決めています．環境が変わると調整し直す必要があるかもしれません）．また，画像の大きさも同時に64x64に変更しています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UkQyA1i6Q5BB"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"HalfCheetahBulletEnv-v0\")\n",
        "# カメラのパラメータを与えてカメラの位置と角度，画像の大きさを調整\n",
        "env = GymWrapper_PyBullet(\n",
        "    env, cam_dist=2, cam_pitch=0, render_width=64, render_height=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofJaPcapRiHK"
      },
      "source": [
        "もう一度画像を確認してみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z33JbCqOQ-6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "69920f43-1963-499a-9064-34cad0d4f150"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env.reset()\n",
        "image = env.render(mode=\"rgb_array\")\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOeH1hMgRkQq"
      },
      "source": [
        "カメラの位置が変わりました．これで元の観測より学習データとして扱いやすくなったと思います．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S_8zY_zSAoz"
      },
      "source": [
        "また，より環境を扱いやすくするために，同じ行動を何度か繰り返すラッパーを挟みます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RaNhyssqRhXm"
      },
      "outputs": [],
      "source": [
        "class RepeatAction(gym.Wrapper):\n",
        "    \"\"\"\n",
        "    同じ行動を指定された回数自動的に繰り返すラッパー．観測は最後の行動に対応するものになる\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env: GymWrapper_PyBullet, skip: int = 4) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env : GymWrapper_PyBullet\n",
        "            環境のインスタンス．今回は先程定義したラッパーでラップした環境を利用する．\n",
        "        skip : int\n",
        "            同じ行動を繰り返す回数．\n",
        "        \"\"\"\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def reset(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        環境をリセットするためのメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (width, height, 3)\n",
        "            環境をリセットしたときの初期の観測．\n",
        "        \"\"\"\n",
        "        return self.env.reset()\n",
        "\n",
        "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):\n",
        "        \"\"\"\n",
        "        環境に行動を与え次の観測，報酬，終了フラグを取得するメソッド．\n",
        "        与えられた行動をskipの回数だけ繰り返した結果を返す．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        action : np.ndarray (action_dim, )\n",
        "            与える行動．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : np.ndarray (width, height, 3)\n",
        "            行動をskipの回数だけ繰り返したあとの観測．\n",
        "        total_reawrd : float\n",
        "            行動をskipの回数だけ繰り返したときの報酬和．\n",
        "        done : bool\n",
        "            エピソードが終了したかどうか表すフラグ．\n",
        "        info : dict\n",
        "            その他の環境に関する情報．\n",
        "        \"\"\"\n",
        "        total_reward = 0.0\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cOMwPsSSQqD"
      },
      "source": [
        "以上でラッパーに関する話は終わりです．これまでに作成したラッパーをまとめて適用し，最終的に用いる環境を作成する関数を実装して，本題のアルゴリズムの実装に移りましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q18Zg5DmSKhe"
      },
      "outputs": [],
      "source": [
        "def make_env() -> RepeatAction:\n",
        "    \"\"\"\n",
        "    作成たラッパーをまとめて適用して環境を作成する関数．\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    env : RepeatAction\n",
        "        ラッパーを適用した環境．\n",
        "    \"\"\"\n",
        "    env = gym.make(\"HalfCheetahBulletEnv-v0\")  # 環境を読み込む．今回はHalfCheetah\n",
        "    # Dreamerでは観測は64x64のRGB画像\n",
        "    env = GymWrapper_PyBullet(\n",
        "        env, cam_dist=2, cam_pitch=0, render_width=64, render_height=64\n",
        "    )\n",
        "    env = RepeatAction(env, skip=2)  # DreamerではActionRepeatは2\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3rWEGtkA3e_"
      },
      "source": [
        "## 3.RSSM\n",
        "RSSMは以下のパーツに分けることができます．\n",
        "\n",
        "**Deterministic state model:**\n",
        "> $h_{t}=f(h_{t-1}, s_{t-1}, a_{t-1})$\n",
        "\n",
        "**Stochastic state model:**\n",
        "> $s_{t}$ ~ $p(s_{t} | h_{t})$\n",
        "\n",
        "**Observation model:**\n",
        "> $o_{t}$ ~ $p(o_{t} | h_{t}, s_{t})$\n",
        "\n",
        "**Reward model:**\n",
        "> $r_{t}$~ $p(r_{t} | h_{t}, s_{t})$\n",
        "\n",
        "[以下の画像](https://towardsai.net/p/machine-learning/dreamer-8b5a42acebbf)は1つの時間ステップでのRSSMの挙動を示しています．\n",
        "\n",
        "![1stepあたりの模式図](https://cdn-images-1.medium.com/max/1024/1*4b2l7Fr4eavQV5ZMouCT-g.png)\n",
        "\n",
        "\n",
        "\n",
        "Deterministic state modelで，RNNは，前の時間ステップの行動$a_{t-1}$と事後確率状態$s'_{t-1}$，決定論的状態$h_{t-1}$を入力とし，決定論的状態$h_t$を出力します．\n",
        "\n",
        "$h_{t}$は (1)事前状態確率$s_{t}$を計算するために，1つの隠れ層を持つMLPに供給され （本実装では線形変換），(2)事後確率状態$s'_{t}$を計算するために，画像埋め込み$e_t$（本実装では`embedded_obs`と表現される）と連結され，別の単層MLP（線形変換）に供給されます．\n",
        "\n",
        "その後，$h_{t}$と$s'_{t}$を連結したものを用いて，画像や報酬などを再構成します．\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJfU7ygCMeJn"
      },
      "source": [
        "## 4.RSSMの実装\n",
        "\n",
        "\n",
        "上記をもとにRSSMの実装を行います．実装では，以下の3つのクラスに分けて実装します．\n",
        "\n",
        "* 状態遷移を担うクラス(TransitionModel)\n",
        "* 観測を復元するデコーダクラス(ObservationMode)\n",
        "* 報酬を予測するクラス(RewardModel)\n",
        "\n",
        "※TransitionModelは上記Deterministic state model, Stochastic state modelを合体させています．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXXUwovNMeJq"
      },
      "source": [
        "まず実装するのがTransitionModelです．\n",
        "\n",
        "1ステップ先の未来の状態表現を予測する機能を担います．\n",
        "\n",
        "学習の方針として，状態遷移を用いた1ステップ先の未来の状態表現の分布である\"prior\"と，1ステップ先の観測の情報を取り込んで計算した状態表現の分布である\"posterior\"が一致するように学習します．\n",
        "\n",
        "\"posterior\"は後に観測の再構成誤差と報酬の予測誤差によって学習されるので，\"posterior\"は上記の2つの誤差によって妥当な状態表現になるように学習され，同時に\"prior\"をそれに近づけることで，状態表現の空間で未来の予測が可能になるように学習する，というイメージです．よって，これを踏まえたクラスの実装になっています．\n",
        "\n",
        "状態表現として，決定的な状態である\"rnn_hidden\"と，確率的な状態である\"state\"の両方を持っています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bUt9Lp3HMeJq"
      },
      "outputs": [],
      "source": [
        "class TransitionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    状態遷移を担うクラス．このクラスは複数の要素を含んでいます．\n",
        "    決定的状態遷移 （RNN) : h_t+1 = f(h_t, s_t, a_t)\n",
        "    確率的状態遷移による1ステップ予測として定義される \"prior\" : p(s_t+1 | h_t+1)\n",
        "    観測の情報を取り込んで定義される \"posterior\": q(s_t+1 | h_t+1, e_t+1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        state_dim: int,\n",
        "        action_dim: int,\n",
        "        rnn_hidden_dim: int,\n",
        "        hidden_dim: int = 200,\n",
        "        min_stddev: float = 0.1,\n",
        "        act: \"function\" = F.elu,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state_dim : int\n",
        "            確率的状態sの次元数．\n",
        "        action_dim : int\n",
        "            行動空間の次元数．\n",
        "        rnn_hidden_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        hidden_dim : int\n",
        "            線形層(fc_state_action, fc_rnn_hidden, fc_rnn_hidden_embedded_obs)の\n",
        "            出力の次元数．\n",
        "        min_stddev : float\n",
        "            確率状態遷移の標準偏差の最小値．\n",
        "        act : function\n",
        "            活性化関数．\n",
        "        \"\"\"\n",
        "        super(TransitionModel, self).__init__()\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.rnn_hidden_dim = rnn_hidden_dim\n",
        "        self.fc_state_action = nn.Linear(state_dim + action_dim, hidden_dim)\n",
        "\n",
        "        self.fc_rnn_hidden = nn.Linear(rnn_hidden_dim, hidden_dim)\n",
        "        self.fc_state_mean_prior = nn.Linear(hidden_dim, state_dim)\n",
        "        self.fc_state_stddev_prior = nn.Linear(hidden_dim, state_dim)\n",
        "        self.fc_rnn_hidden_embedded_obs = nn.Linear(rnn_hidden_dim + 1024, hidden_dim)\n",
        "        self.fc_state_mean_posterior = nn.Linear(hidden_dim, state_dim)\n",
        "        self.fc_state_stddev_posterior = nn.Linear(hidden_dim, state_dim)\n",
        "\n",
        "        # next hidden stateを計算\n",
        "        self.rnn = nn.GRUCell(hidden_dim, rnn_hidden_dim)\n",
        "        self._min_stddev = min_stddev\n",
        "        self.act = act\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        state: torch.Tensor,\n",
        "        action: torch.Tensor,\n",
        "        rnn_hidden: torch.Tensor,\n",
        "        embedded_next_obs: torch.Tensor,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        prior p(s_t+1 | h_t+1) と posterior q(s_t+1 | h_t+1, e_t+1) を返すメソッド．\n",
        "        この2つが近づくように学習する．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            時刻tの状態(s_t)．\n",
        "        action : torch.Tensor (batch size, action dim)\n",
        "            時刻tの行動(a_t)．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持している決定的状態(h_t)．\n",
        "        embedded_next_obs : torch.Tensor (batch size, 1024)\n",
        "            時刻t+1の観測をエンコードしたもの(e_t+1)．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        next_state_prior : torch.Tensor (batch size, state dim)\n",
        "            prior(p(s_t+1 | h_t+1))による次の時刻の状態の予測．\n",
        "        next_state_posterior : torch.Tensor (batch size, state dim)\n",
        "            posterior(q(s_t+1 | h_t+1, e_t+1))による次の時刻の状態の予測．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持する次の決定的状態(h_t+1)．\n",
        "        \"\"\"\n",
        "        next_state_prior, rnn_hidden = self.prior(\n",
        "            self.recurrent(state, action, rnn_hidden)\n",
        "        )\n",
        "        next_state_posterior = self.posterior(rnn_hidden, embedded_next_obs)\n",
        "        return next_state_prior, next_state_posterior, rnn_hidden\n",
        "\n",
        "    def recurrent(\n",
        "        self, state: torch.Tensor, action: torch.Tensor, rnn_hidden: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        決定的状態 h_t+1 = f(h_t, s_t, a_t)を計算するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            時刻tの状態(s_t)．\n",
        "        action : torch.Tensor (batch size, action dim)\n",
        "            時刻tの行動(a_t)．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持している決定的状態(h_t)．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持する次の決定的状態(h_t+1)．\n",
        "        \"\"\"\n",
        "        hidden = self.act(self.fc_state_action(torch.cat([state, action], dim=1)))\n",
        "        # h_t+1を求める\n",
        "        rnn_hidden = self.rnn(hidden, rnn_hidden)\n",
        "        return rnn_hidden\n",
        "\n",
        "    def prior(self, rnn_hidden: torch.Tensor) -> Tuple[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        prior p(s_t+1 | h_t+1) を計算するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持している決定的状態(h_t+1)．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            決定的状態を用いてサンプリングされた確率的な状態(s_t+1)．\n",
        "            ここでは決定的状態h_t+1からガウス分布の平均，標準偏差を推定してサンプリングしています．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持する決定的状態(h_t+1)．\n",
        "            入力からのものをそのまま返しています．\n",
        "        \"\"\"\n",
        "        #h_t+1を求める（ヒント: self.act, self.fc_rnn_hiddenを使用）\n",
        "        hidden = self.act(self.fc_rnn_hidden(rnn_hidden))  # WRITE ME\n",
        "\n",
        "        mean = self.fc_state_mean_prior(hidden)\n",
        "        stddev = F.softplus(self.fc_state_stddev_prior(hidden)) + self._min_stddev\n",
        "        return Normal(mean, stddev), rnn_hidden\n",
        "\n",
        "    def posterior(\n",
        "        self, rnn_hidden: torch.Tensor, embedded_obs: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        posterior q(s_t+1 | h_t+1, e_t+1)  を計算するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn hidden dim)\n",
        "            RNNが保持している決定的状態(h_t+1)．\n",
        "        embedded_obs : torch.Tensor (batch size, 1024)\n",
        "            時刻t+1の観測をエンコードしたもの．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            決定的状態とエンコードした観測を用いてサンプリングされた確率的な状態(s_t+1)．\n",
        "            ここでは決定的状態h_t+1とエンコードした観測e_t+1からガウス分布の平均，標準偏差を推定してサンプリングしています．\n",
        "        \"\"\"\n",
        "        # h_t+1，o_t+1を結合し，q(s_t+1 | h_t+1, e_t+1) を計算する\n",
        "        hidden = self.fc_rnn_hidden_embedded_obs(torch.cat([rnn_hidden, embedded_obs], dim=1)) # WRITE ME\n",
        "        mean = self.fc_state_mean_posterior(hidden)\n",
        "        stddev = F.softplus(self.fc_state_stddev_posterior(hidden)) + self._min_stddev\n",
        "        return Normal(mean, stddev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k4Pcf0qMeJq"
      },
      "source": [
        "次に，観測を再構成するデコーダを実装します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VmsUzBFYMeJq"
      },
      "outputs": [],
      "source": [
        "class ObservationModel(nn.Module):\n",
        "    \"\"\"\n",
        "    p(o_t | s_t, h_t)\n",
        "    低次元の状態表現から画像を再構成するデコーダ (3, 64, 64)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, state_dim: int, rnn_hidden_dim: int) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state_dim : int\n",
        "            確率的状態sの次元数．\n",
        "        rnn_hidden_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        \"\"\"\n",
        "        super(ObservationModel, self).__init__()\n",
        "        self.fc = nn.Linear(state_dim + rnn_hidden_dim, 1024)\n",
        "        self.dc1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=2)\n",
        "        self.dc2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        self.dc3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        self.dc4 = nn.ConvTranspose2d(32, 3, kernel_size=6, stride=2)\n",
        "\n",
        "    def forward(self, state: torch.Tensor, rnn_hidden: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．確率的状態sと決定的状態hから観測を再構成する．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            確率的状態s．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
        "            決定的状態h．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs : torch.Tensor (batch size, 3, 64, 64)\n",
        "            再構成された観測o．\n",
        "        \"\"\"\n",
        "        hidden = self.fc(torch.cat([state, rnn_hidden], dim=1))\n",
        "        hidden = hidden.view(hidden.size(0), 1024, 1, 1)\n",
        "        hidden = F.relu(self.dc1(hidden))\n",
        "        hidden = F.relu(self.dc2(hidden))\n",
        "        hidden = F.relu(self.dc3(hidden))\n",
        "        obs = self.dc4(hidden)\n",
        "        return obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duKz6wCto9Fa"
      },
      "source": [
        "次に，報酬を予測するRewardモデルを実装します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4c0l4yGSo9Fk"
      },
      "outputs": [],
      "source": [
        "class RewardModel(nn.Module):\n",
        "    \"\"\"\n",
        "    p(r_t | s_t, h_t)\n",
        "    低次元の状態表現から報酬を予測する．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        state_dim: int,\n",
        "        rnn_hidden_dim: int,\n",
        "        hidden_dim: int = 400,\n",
        "        act: \"function\" = F.elu,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state_dim : int\n",
        "            確率的状態sの次元数．\n",
        "        rnn_hidden_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        hidden_dim : int\n",
        "            報酬モデルの隠れ層の次元数． (default=400)\n",
        "        act : function\n",
        "            報酬モデルに利用される活性化関数． (default=torch.nn.functional.elu)\n",
        "        \"\"\"\n",
        "        super(RewardModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim + rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
        "        self.act = act\n",
        "\n",
        "    def forward(self, state: torch.Tensor, rnn_hidden: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．確率的状態sと決定的状態hから報酬rを推定する．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            確率的状態s．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
        "            決定的状態h．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        reward : torch.Tensor (batch size, 1)\n",
        "            確率的状態s，決定的状態hに対する報酬r．\n",
        "        \"\"\"\n",
        "        hidden = self.act(self.fc1(torch.cat([state, rnn_hidden], dim=1)))\n",
        "        hidden = self.act(self.fc2(hidden))\n",
        "        hidden = self.act(self.fc3(hidden))\n",
        "        reward = self.fc4(hidden)\n",
        "        return reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgNNwwpaMYBi"
      },
      "source": [
        "最後に，上記で定義された３つのモデルを`RSSM`クラスとしてまとめます.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QzJB9ZiOxMnn"
      },
      "outputs": [],
      "source": [
        "class RSSM:\n",
        "    \"\"\"\n",
        "    TransitionModel, ObservationModel, RewardModelの3つをまとめたRSSMクラス．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        state_dim: int,\n",
        "        action_dim: int,\n",
        "        rnn_hidden_dim: int,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state_dim : int\n",
        "            確率的状態sの次元数．\n",
        "        action_dim : int\n",
        "            行動空間の次元数．\n",
        "        rnn_hidden_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        \"\"\"\n",
        "        self.transition = TransitionModel(state_dim, action_dim, rnn_hidden_dim).to(\n",
        "            device\n",
        "        )\n",
        "        self.observation = ObservationModel(\n",
        "            state_dim,\n",
        "            rnn_hidden_dim,\n",
        "        ).to(device)\n",
        "        self.reward = RewardModel(\n",
        "            state_dim,\n",
        "            rnn_hidden_dim,\n",
        "        ).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhlVvU3aZ5FC"
      },
      "source": [
        "## 5.補助機能の実装\n",
        "\n",
        "モデルの実装の前に，いくつか学習上必要になる補助機能を実装しておきましょう．具体的にはリプレイバッファ，観測の前処理を行う関数，λ-returnを計算する関数 の3つです．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REs6Pq7paPJX"
      },
      "source": [
        "まずはリプレイバッファを実装します．ただし，RNNを使う関係上一連の系列として経験をサンプルしてくる必要があるため，DQNの時よりは少し実装に工夫が必要です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-3bnTX7mNmOA"
      },
      "outputs": [],
      "source": [
        "# こちらはDQNのReplayBufferの定義\n",
        "class ReplayBuffer:\n",
        "    \"\"\"\n",
        "    これまでの経験をためておくリプレイバッファ．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, memory_size: int) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        memory_size : int\n",
        "            リプレイバッファに貯められるデータの上限．\n",
        "        \"\"\"\n",
        "        self.memory_size = memory_size\n",
        "        # 収集する経験は上限を決め古いものから削除する．\n",
        "        self.memory = deque([], maxlen=memory_size)\n",
        "\n",
        "    def append(self, transition: dict) -> None:\n",
        "        \"\"\"\n",
        "        環境から得た経験（状態，行動，次の状態，報酬，終了フラグ）をキューに追加するメソッド．\n",
        "        dequeを用いているため上限(memory_size)に達すると古いものが削除される．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        trainsition : dict\n",
        "            状態(state)，次の状態(next_state)，報酬(reward)，行動(action)，終了フラグ(done)を格納した辞書．\n",
        "        \"\"\"\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def sample(self, batch_size: int) -> dict:  # 貯めた経験の中からランダムにミニバッチ単位で経験を取り出す．\n",
        "        \"\"\"\n",
        "        バッファに貯めた経験の中からランダムにミニバッチ単位で経験を取り出すメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size : int\n",
        "            バッチサイズ．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        sample : dict\n",
        "            状態(states)，次の状態(next_states)，報酬(rewards)，行動(actions)，終了フラグ(dones)をバッチサイズ分だけ格納した辞書．\n",
        "        \"\"\"\n",
        "        batch_indexes = np.random.randint(0, len(self.memory), size=batch_size)\n",
        "        states = np.array([self.memory[index][\"state\"] for index in batch_indexes])\n",
        "        next_states = np.array(\n",
        "            [self.memory[index][\"next_state\"] for index in batch_indexes]\n",
        "        )\n",
        "        rewards = np.array([self.memory[index][\"reward\"] for index in batch_indexes])\n",
        "        actions = np.array([self.memory[index][\"action\"] for index in batch_indexes])\n",
        "        dones = np.array([self.memory[index][\"done\"] for index in batch_indexes])\n",
        "        return {\n",
        "            \"states\": states,\n",
        "            \"next_states\": next_states,\n",
        "            \"rewards\": rewards,\n",
        "            \"actions\": actions,\n",
        "            \"dones\": dones,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tmptCR67aYZc"
      },
      "outputs": [],
      "source": [
        "# 　今回のReplayBuffer\n",
        "class ReplayBuffer(object):\n",
        "    \"\"\"\n",
        "    RNNを用いて訓練するのに適したリプレイバッファ．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, capacity: int, observation_shape: List[int], action_dim: int\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        capacity : int\n",
        "            リプレイバッファにためておくことができる経験の上限．\n",
        "        observation_shape : List[int]\n",
        "            環境から与えられる観測の形状．\n",
        "        action_dim : int\n",
        "            行動空間の次元数．\n",
        "        \"\"\"\n",
        "        self.capacity = capacity\n",
        "\n",
        "        self.observations = np.zeros((capacity, *observation_shape), dtype=np.uint8)\n",
        "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "        self.rewards = np.zeros((capacity, 1), dtype=np.float32)\n",
        "        self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "        # self.done = np.zeros((capacity, 1), dtype=np.bool)\n",
        "\n",
        "        self.index = 0\n",
        "        self.is_filled = False\n",
        "\n",
        "    def push(\n",
        "        self, observation: np.ndarray, action: np.ndarray, reward: float, done: bool\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        リプレイバッファに経験を追加するメソッド．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        observation : np.ndarray (64, 64, 3)\n",
        "            環境から得られた観測．\n",
        "        action : np.ndarray (action_dim, )\n",
        "            エージェントがとった（もしくは経験を貯める際のランダムな）行動．\n",
        "        reward : float\n",
        "            観測に対して行動をとったときに得られる報酬．\n",
        "        done : bool\n",
        "            エピソードが終了するかどうかのフラグ．\n",
        "        \"\"\"\n",
        "        self.observations[self.index] = observation\n",
        "        self.actions[self.index] = action\n",
        "        self.rewards[self.index] = reward\n",
        "        self.done[self.index] = done\n",
        "\n",
        "        # indexは巡回し，最も古い経験を上書きする\n",
        "        if self.index == self.capacity - 1:\n",
        "            self.is_filled = True\n",
        "        self.index = (self.index + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size: int, chunk_length: int) -> Tuple[np.ndarray]:\n",
        "        \"\"\"\n",
        "        経験をリプレイバッファからサンプルします．（ほぼ）一様なサンプルです．\n",
        "        結果として返ってくるのは観測（画像），行動，報酬，終了シグナルについての(batch_size, chunk_length, 各要素の次元)の配列です．\n",
        "        各バッチは連続した経験になっています．\n",
        "        注意: chunk_lengthをあまり大きな値にすると問題が発生する場合があります．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size : int\n",
        "            バッチサイズ．\n",
        "        chunk_length : int\n",
        "            バッチあたりの系列長．\n",
        "\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        sampled_observations : np.ndarray (batch size, chunk length, 3, 64, 64)\n",
        "            バッファからサンプリングされた観測．\n",
        "        sampled_actions : np.ndarray (batch size, chunk length, action dim)\n",
        "            バッファからサンプリングされた行動．\n",
        "        sampled_rewards : np.ndarray (batch size, chunk length, 1)\n",
        "            バッファからサンプリングされた報酬．\n",
        "        sampled_rewards : np.ndarray (batch size, chunk length, 1)\n",
        "            バッファからサンプリングされたエピソードの終了フラグ．\n",
        "        \"\"\"\n",
        "        episode_borders = np.where(self.done)[0]\n",
        "        sampled_indexes = []\n",
        "        for _ in range(batch_size):\n",
        "            cross_border = True\n",
        "            while cross_border:\n",
        "                initial_index = np.random.randint(len(self) - chunk_length + 1)\n",
        "                final_index = initial_index + chunk_length - 1\n",
        "                cross_border = np.logical_and(\n",
        "                    initial_index <= episode_borders, episode_borders < final_index\n",
        "                ).any()  # 論理積\n",
        "            sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "        sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "            batch_size, chunk_length, *self.observations.shape[1:]\n",
        "        )\n",
        "        sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "            batch_size, chunk_length, self.actions.shape[1]\n",
        "        )\n",
        "        sampled_rewards = self.rewards[sampled_indexes].reshape(\n",
        "            batch_size, chunk_length, 1\n",
        "        )\n",
        "        sampled_done = self.done[sampled_indexes].reshape(batch_size, chunk_length, 1)\n",
        "        return sampled_observations, sampled_actions, sampled_rewards, sampled_done\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        バッファに貯められている経験の数を返すメソッド．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        length : int\n",
        "            バッファに貯められている経験の数．\n",
        "        \"\"\"\n",
        "        return self.capacity if self.is_filled else self.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RcSzdDcaUsa"
      },
      "source": [
        "次に観測の前処理を行う関数を実装します．ちなみに，これもラッパーとして最初から適用してしまわないのは，リプレイバッファにはより容量の小さなnp．uint8の形式で保存しておきたいためです．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MLIt0qiya1_2"
      },
      "outputs": [],
      "source": [
        "def preprocess_obs(obs: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    画像を正規化する．[0, 255] -> [-0.5, 0.5]．\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    obs : np.ndarray (64, 64, 3) or (chank length, batch size, 3, 64, 64)\n",
        "        環境から得られた観測．画素値は[0, 255]．\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    normalized_obs : np.ndarray (64, 64, 3) or (chank length, batch size, 64, 64, 3)\n",
        "        画素値を[-0.5, 0.5]で正規化した観測．\n",
        "    \"\"\"\n",
        "    obs = obs.astype(np.float32)\n",
        "    normalized_obs = obs / 255.0 - 0.5\n",
        "    return normalized_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD5tQXKea4lA"
      },
      "source": [
        "Dreamerでは価値関数の学習を行いますが，このために通常のTD誤差ではなく，**TD(λ)をベースにしたλ-return**としてターゲット価値を計算し，それと現在の予測価値の誤差を用います．そのためにλ-returnを計算する関数をここで実装しておきます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fLZMKJj_bIHr"
      },
      "outputs": [],
      "source": [
        "def lambda_target(\n",
        "    rewards: torch.Tensor, values: torch.Tensor, gamma: float, lambda_: float\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    価値関数の学習のためのλ-returnを計算する関数．\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rewards : torch.Tensor (imagination_horizon+1,  batch size * (chank length - 1))\n",
        "        報酬モデルによる報酬の推定値．\n",
        "    values : torch.Tensor (imagination_horizon+1,  batch size * (chank length - 1))\n",
        "        価値関数を近似するValueモデルによる状態価値関数の推定値．\n",
        "    gamma : float\n",
        "        割引率．\n",
        "    lambda_ : float\n",
        "        λ-returnのパラメータλ．\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    V_lambda : torch.Tensor (imagination_horizon+1, batch size * (chank length - 1))\n",
        "        各状態に対するλ-returnの値．\n",
        "    \"\"\"\n",
        "    V_lambda = torch.zeros_like(rewards, device=rewards.device)\n",
        "\n",
        "    H = rewards.shape[0] - 1\n",
        "    V_n = torch.zeros_like(rewards, device=rewards.device)\n",
        "    V_n[H] = values[H]\n",
        "    for n in range(1, H + 1):\n",
        "        # まずn-step returnを計算します\n",
        "        # 注意: 系列が途中で終わってしまったら，可能な中で最大のnを用いたn-stepを使います\n",
        "        V_n[:-n] = (gamma**n) * values[n:]\n",
        "        for k in range(1, n + 1):\n",
        "            if k == n:\n",
        "                V_n[:-n] += (gamma ** (n - 1)) * rewards[k:]\n",
        "            else:\n",
        "                V_n[:-n] += (gamma ** (k - 1)) * rewards[k : -n + k]\n",
        "\n",
        "        # lambda_でn-step returnを重みづけてλ-returnを計算します\n",
        "        if n == H:\n",
        "            V_lambda += (lambda_ ** (H - 1)) * V_n\n",
        "        else:\n",
        "            V_lambda += (1 - lambda_) * (lambda_ ** (n - 1)) * V_n\n",
        "\n",
        "    return V_lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keAW0J-qS24Q"
      },
      "source": [
        "## 6.Dreamerの実装\n",
        "\n",
        "続いてDreamerの実装です．Dreamerの実装では以下の3クラスは上で定義したRSSMの各クラスと同義ですので，\n",
        "改めて定義はしておらず`RSSM`クラスを呼び出して使用することとします．\n",
        "* 状態遷移を担うクラス(TransitionModel)\n",
        "* 観測を復元するデコーダクラス(ObservationModel)\n",
        "* 報酬を予測するクラス(RewardModel)\n",
        "\n",
        "\n",
        "そのため，新たに定義するモデルは，以下の３つのみになります．\n",
        "* 観測の画像をベクトルに変換するエンコーダクラス(Encoder)\n",
        "* 価値関数を計算するクラス(ValueModel)\n",
        "* 実際に行動を決定するクラス(ActionModel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_ARrbicUZzP"
      },
      "source": [
        "まずエンコーダを実装します．ここでは，CNN(Convolutional Neural Network)を用いて，観測の画像をベクトルに変換します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kGY-YZzmSh-3"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    (3, 64, 64)の画像を(1024,)のベクトルに変換するエンコーダクラス．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "        層の定義のみを行う．\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.cv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2)\n",
        "        self.cv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.cv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
        "        self.cv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．観測画像をベクトルに埋め込む．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        obs : torch.Tensor (64, 64, 3)\n",
        "            環境から得られた観測画像．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        embedded_obs : torch.Tensor (batch size, 1024)\n",
        "            観測を1024次元のベクトルに埋め込んだもの．\n",
        "        \"\"\"\n",
        "        hidden = F.relu(self.cv1(obs))\n",
        "        hidden = F.relu(self.cv2(hidden))\n",
        "        hidden = F.relu(self.cv3(hidden))\n",
        "        embedded_obs = F.relu(self.cv4(hidden)).reshape(hidden.size(0), -1)\n",
        "        return embedded_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7coVKT3AWMx3"
      },
      "source": [
        "ここからがDreamerの中核となる部分で，RSSMの学習を通して獲得された低次元の状態表現の上でActor-Criticを行います.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVY3TCdWx2L"
      },
      "source": [
        "以下で，価値関数を近似するValueモデル $v_{\\phi}(s_{\\tau})　\\approx E_{q(.|s_{\\tau})}(\\sum_{\\tau=t}^{t+H}(\\gamma^{\\tau-t}r_{\\tau}) )$ を実装します．Q学習などで用いられる状態行動価値関数Q(s, a)ではなく，状態価値関数V(s)であることに多少の注意が必要です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4gegVfLVWLLR"
      },
      "outputs": [],
      "source": [
        "class ValueModel(nn.Module):\n",
        "    \"\"\"\n",
        "    低次元の状態表現(state_dim + rnn_hidden_dim)から状態価値を出力するクラス．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        state_dim: int,\n",
        "        rnn_hidden_dim: int,\n",
        "        hidden_dim: int = 400,\n",
        "        act: \"function\" = F.elu,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state_dim : int\n",
        "            確率的状態sの次元数．\n",
        "        rnn_hidden_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        hidden_dim : int\n",
        "            モデルの隠れ層の次元数． (default=400)\n",
        "        act : function\n",
        "            モデルの活性化関数． (default=torch.nn.functional.elu)\n",
        "        \"\"\"\n",
        "        super(ValueModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim + rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
        "        self.act = act\n",
        "\n",
        "    def forward(self, state: torch.Tensor, rnn_hidden: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．低次元の状態表現から状態価値を推定する．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state : torch.Tensor (batch size, state dim)\n",
        "            確率的状態s．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
        "            決定的状態h．\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        state_value : torch.Tensor (batch size, 1)\n",
        "            入力された状態に対する状態価値の推定値．\n",
        "        \"\"\"\n",
        "        hidden = self.act(self.fc1(torch.cat([state, rnn_hidden], dim=1)))\n",
        "        hidden = self.act(self.fc2(hidden))\n",
        "        hidden = self.act(self.fc3(hidden))\n",
        "        state_value = self.fc4(hidden)\n",
        "        return state_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adOXp2TRXQ_Y"
      },
      "source": [
        "最後です．実際に行動を出力するActionモデル $a_{\\tau} \\sim q_{\\delta}(a_{\\tau}|s_{\\tau})$ を実装します．\n",
        "\n",
        "Actionモデルは価値の見積もりを最大化することを目的とします．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_2iSa_-kW_W7"
      },
      "outputs": [],
      "source": [
        "class ActionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    低次元の状態表現(state_dim + rnn_hidden_dim)から行動を計算するクラス．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        state_dim: int,\n",
        "        rnn_hidden_dim: int,\n",
        "        action_dim: int,\n",
        "        hidden_dim: int = 400,\n",
        "        act: \"function\" = F.elu,\n",
        "        min_stddev: float = 1e-4,\n",
        "        init_stddev: float = 5.0,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        state_dim : int\n",
        "            確率的状態sの次元数．\n",
        "        rnn_hidden_dim : int\n",
        "            決定的状態hの次元数．\n",
        "        action_dim : int\n",
        "            行動空間の次元数．\n",
        "        hidden_dim : int\n",
        "            モデルの隠れ層の次元数． (default=400)\n",
        "        act : function\n",
        "            モデルの活性化関数． (default=torch.nn.functional.elu)\n",
        "        min_stddev : float\n",
        "            行動をサンプリングする分布の標準偏差の最小値． (default=1e-4)\n",
        "        init_stddev : float\n",
        "            行動をサンプリングする分布の標準偏差の初期値． (default=5.0)\n",
        "        \"\"\"\n",
        "        super(ActionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim + rnn_hidden_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_mean = nn.Linear(hidden_dim, action_dim)\n",
        "        self.fc_stddev = nn.Linear(hidden_dim, action_dim)\n",
        "        self.act = act\n",
        "        self.min_stddev = min_stddev\n",
        "        self.init_stddev = np.log(np.exp(init_stddev) - 1)\n",
        "\n",
        "    def forward(\n",
        "        self, state: torch.Tensor, rnn_hidden: torch.Tensor, training: bool = True\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        順伝播を行うメソッド．入力された状態に対する行動を出力する．\n",
        "        training=Trueなら，NNのパラメータに関して微分可能な形の行動のサンプル（Reparametrizationによる）を返す．\n",
        "        training=Falseなら，行動の確率分布の平均値を返す．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        staet : torch.Tensor (batch size, state dim)\n",
        "            確率的状態s．\n",
        "        rnn_hidden : torch.Tensor (batch size, rnn_hidden_dim)\n",
        "            決定的状態h．\n",
        "        training : bool\n",
        "            訓練か推論かを示すフラグ． (default=True)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action : torch.Tensor (batch size, action dim)\n",
        "            入力された状態に対する行動．\n",
        "            training=Trueでは微分可能な形の行動をサンプリングした値，\n",
        "            training=Falseでは行動の確率分布の平均値を返す．\n",
        "        \"\"\"\n",
        "        hidden = self.act(self.fc1(torch.cat([state, rnn_hidden], dim=1)))\n",
        "        hidden = self.act(self.fc2(hidden))\n",
        "        hidden = self.act(self.fc3(hidden))\n",
        "        hidden = self.act(self.fc4(hidden))\n",
        "\n",
        "        # Dreamerの実装に合わせて少し平均と分散に対する簡単な変換が入っています\n",
        "        mean = self.fc_mean(hidden)\n",
        "        mean = 5.0 * torch.tanh(mean / 5.0)\n",
        "        stddev = self.fc_stddev(hidden)\n",
        "        stddev = F.softplus(stddev + self.init_stddev) + self.min_stddev\n",
        "\n",
        "        if training:\n",
        "            action = torch.tanh(Normal(mean, stddev).rsample())  # 微分可能にするためrsample()\n",
        "        else:\n",
        "            action = torch.tanh(mean)\n",
        "        return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5L46nAhYAAJ"
      },
      "source": [
        "実装の詳細まで掴みきれなくとも，個々のクラスが担っている役割が大雑把にでもわかっていただければ幸いです."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdKZ1S2_boOd"
      },
      "source": [
        "## 7.エージェントの実装\n",
        "\n",
        "Dreamerでは行動を計算するために低次元の状態表現が必要で，この状態表現はRSSMを用いて計算されるため，テスト時もこの状態表現のためにRSSMによる推論を行い続ける必要があります．\n",
        "\n",
        "そのため，先ほど実装したActionModelをそのまま使っても簡単には行動を決定できません．\n",
        "\n",
        "ここを扱いやすくするために，RSSMを使って低次元の状態表現を計算しつつ，行動を決定するAgentクラスを実装します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Dof4rokgYj-6"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    \"\"\"\n",
        "    ActionModelに基づき行動を決定する．そのためにRSSMを用いて状態表現をリアルタイムで推論して維持するクラス．\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder: Encoder, rssm: RSSM, action_model: ActionModel) -> None:\n",
        "        \"\"\"\n",
        "        コンストラクタ．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        encoder : Encoder\n",
        "            上で定義したEncoderクラスのインスタンス．\n",
        "            観測画像を1024次元のベクトルに埋め込む ．\n",
        "        rssm : RSSM\n",
        "            上で定義したRSSMクラスのインスタンス．\n",
        "            遷移モデル，1024次元のベクトルを観測画像にするデコーダ，報酬を予測するモデルを持つ．\n",
        "        action_model : ActionModel\n",
        "            上で定義したActionModelのインスタンス．\n",
        "            低次元の状態表現から行動を予測する．\n",
        "        \"\"\"\n",
        "        self.encoder = encoder\n",
        "        self.rssm = rssm\n",
        "        self.action_model = action_model\n",
        "\n",
        "        self.device = next(self.action_model.parameters()).device\n",
        "        self.rnn_hidden = torch.zeros(1, rssm.rnn_hidden_dim, device=self.device)\n",
        "\n",
        "    def __call__(self, obs: np.ndarray, training=True) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        特殊メソッド．\n",
        "        インスタンスに直接引数を渡すことで実行される．\n",
        "        （例）agent = Agent(*args)\n",
        "             action = agent(obs)  # このときに__call__メソッドが呼び出される．\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        obs : np.ndarray (batch size, 3, 64, 64)\n",
        "            環境から得られた観測画像．\n",
        "        training : bool\n",
        "            訓練か推論かを示すフラグ． (default=True)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action : np.ndarray (batch size, action dim)\n",
        "            入力された観測に対する行動の予測．\n",
        "        \"\"\"\n",
        "        # preprocessを適用，PyTorchのためにChannel-Firstに変換\n",
        "        obs = preprocess_obs(obs)\n",
        "        obs = torch.as_tensor(obs, device=self.device)\n",
        "        obs = obs.transpose(1, 2).transpose(0, 1).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 観測を低次元の表現に変換し，posteriorからのサンプルをActionModelに入力して行動を決定する\n",
        "            embedded_obs = self.encoder(obs)\n",
        "            state_posterior = self.rssm.posterior(self.rnn_hidden, embedded_obs)\n",
        "            state = state_posterior.sample()\n",
        "            action = self.action_model(state, self.rnn_hidden, training=training)\n",
        "\n",
        "            # 次のステップのためにRNNの隠れ状態を更新しておく\n",
        "            _, self.rnn_hidden = self.rssm.prior(\n",
        "                self.rssm.recurrent(state, action, self.rnn_hidden)\n",
        "            )\n",
        "\n",
        "        return action.squeeze().cpu().numpy()\n",
        "\n",
        "    def reset(self) -> None:\n",
        "        \"\"\"\n",
        "        RNNの隠れ状態（=決定的状態）をリセットする．\n",
        "        \"\"\"\n",
        "        self.rnn_hidden = torch.zeros(1, self.rssm.rnn_hidden_dim, device=self.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUPWAkpyc9Z-"
      },
      "source": [
        "## 8.ハイパーパラメータの設定と学習の準備\n",
        "\n",
        "ここまででDreamerの基本的な構成要素は実装が終わりました．あとはハイパーパラメータを設定し，モデルやリプレイバッファを宣言して学習の準備を整えます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z8sW8K5Kdjrg"
      },
      "outputs": [],
      "source": [
        "# リプレイバッファの宣言\n",
        "buffer_capacity = 200000  # Colabのメモリの都合上，元の実装より小さめにとっています\n",
        "replay_buffer = ReplayBuffer(\n",
        "    capacity=buffer_capacity,\n",
        "    observation_shape=env.observation_space.shape,\n",
        "    action_dim=env.action_space.shape[0],\n",
        ")\n",
        "\n",
        "# モデルの宣言\n",
        "state_dim = 30  # 確率的状態の次元\n",
        "rnn_hidden_dim = 200  # 決定的状態（RNNの隠れ状態）の次元\n",
        "# 確率的状態の次元と決定的状態（RNNの隠れ状態）の次元は一致しなくて良い\n",
        "encoder = Encoder().to(device)\n",
        "rssm = RSSM(\n",
        "    state_dim,\n",
        "    env.action_space.shape[0],\n",
        "    rnn_hidden_dim,\n",
        ")\n",
        "value_model = ValueModel(state_dim, rnn_hidden_dim).to(device)\n",
        "action_model = ActionModel(state_dim, rnn_hidden_dim, env.action_space.shape[0]).to(\n",
        "    device\n",
        ")\n",
        "\n",
        "# オプティマイザの宣言\n",
        "model_lr = 6e-4  # encoder, rssm, obs_model, reward_modelの学習率\n",
        "value_lr = 8e-5\n",
        "action_lr = 8e-5\n",
        "eps = 1e-4\n",
        "model_params = (\n",
        "    list(encoder.parameters())\n",
        "    + list(rssm.transition.parameters())\n",
        "    + list(rssm.observation.parameters())\n",
        "    + list(rssm.reward.parameters())\n",
        ")\n",
        "model_optimizer = torch.optim.Adam(model_params, lr=model_lr, eps=eps)\n",
        "value_optimizer = torch.optim.Adam(value_model.parameters(), lr=value_lr, eps=eps)\n",
        "action_optimizer = torch.optim.Adam(action_model.parameters(), lr=action_lr, eps=eps)\n",
        "\n",
        "# その他ハイパーパラメータ\n",
        "seed_episodes = 5  # 最初にランダム行動で探索するエピソード数\n",
        "all_episodes = 15  # 学習全体のエピソード数（300ほどで，ある程度収束します）\n",
        "test_interval = 20  # 何エピソードごとに探索ノイズなしのテストを行うか\n",
        "model_save_interval = 20  # NNの重みを何エピソードごとに保存するか\n",
        "collect_interval = 100  # 何回のNNの更新ごとに経験を集めるか（＝1エピソード経験を集めるごとに何回更新するか）\n",
        "\n",
        "action_noise_var = 0.3  # 探索ノイズの強さ\n",
        "\n",
        "batch_size = 50\n",
        "chunk_length = 50  # 1回の更新で用いる系列の長さ\n",
        "imagination_horizon = 15  # Actor-Criticの更新のために，Dreamerで何ステップ先までの想像上の軌道を生成するか\n",
        "\n",
        "\n",
        "gamma = 0.9  # 割引率\n",
        "lambda_ = 0.95  # λ-returnのパラメータ\n",
        "clip_grad_norm = 100  # gradient clippingの値\n",
        "free_nats = 3  # KL誤差（RSSMのTransitionModelにおけるpriorとposteriorの間の誤差）がこの値以下の場合，無視する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUoI0l9Ee0Tp"
      },
      "source": [
        "## 9.学習\n",
        "まず，最初の数エピソードはランダムに行動して経験をリプレイバッファに貯めます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "txKI9CCne5e3"
      },
      "outputs": [],
      "source": [
        "env = make_env()\n",
        "for episode in range(seed_episodes):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        next_obs, reward, done, _ = env.step(action)\n",
        "        replay_buffer.push(obs, action, reward, done)\n",
        "        obs = next_obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsE7Hu6yfW2B"
      },
      "source": [
        "学習結果を確認するために，TensorBoardを立ち上げておきます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2fmFqkidfEXP"
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs\"\n",
        "writer = SummaryWriter(log_dir)\n",
        "# %tensorboard --logdir='./logs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raG5bSzCfrhV"
      },
      "source": [
        "以下がメインの学習ループです．それぞれのコメントを見て，実装の内容を追ってください.\n",
        "\n",
        "学習にはColab Proで3時間半ぐらいの時間がかかります."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6_LNryZQfnKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe2d83b4-ff1f-4ebe-f3d7-d6669032f7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode [   6/ 100] is collected. Total reward is 1102.253472\n",
            "elasped time for interaction: 4.61s\n",
            "update_step:   1 model loss: 89.64141, kl_loss: 44.92152, obs_loss: 40.60925, reward_loss: 4.11063, value_loss: 0.58146 action_loss: -0.17088\n",
            "update_step:   2 model loss: 64.29022, kl_loss: 19.41825, obs_loss: 40.95669, reward_loss: 3.91529, value_loss: 2.21193 action_loss: -1.00050\n",
            "update_step:   3 model loss: 62.26352, kl_loss: 15.15821, obs_loss: 43.48325, reward_loss: 3.62207, value_loss: 5.94787 action_loss: -2.15756\n",
            "update_step:   4 model loss: 60.04533, kl_loss: 13.37572, obs_loss: 43.34203, reward_loss: 3.32759, value_loss: 14.75229 action_loss: -4.15071\n",
            "update_step:   5 model loss: 52.13242, kl_loss: 11.20197, obs_loss: 38.48616, reward_loss: 2.44429, value_loss: 27.76922 action_loss: -5.60528\n",
            "update_step:   6 model loss: 46.55433, kl_loss: 10.11299, obs_loss: 34.02815, reward_loss: 2.41319, value_loss: 62.40369 action_loss: -9.55917\n",
            "update_step:   7 model loss: 44.74579, kl_loss: 10.79858, obs_loss: 32.08344, reward_loss: 1.86378, value_loss: 83.49586 action_loss: -10.92513\n",
            "update_step:   8 model loss: 44.25657, kl_loss: 12.80757, obs_loss: 29.78465, reward_loss: 1.66435, value_loss: 121.58530 action_loss: -13.59206\n",
            "update_step:   9 model loss: 42.88960, kl_loss: 12.73738, obs_loss: 28.33865, reward_loss: 1.81357, value_loss: 113.77284 action_loss: -13.08571\n",
            "update_step:  10 model loss: 40.97794, kl_loss: 10.25373, obs_loss: 28.89419, reward_loss: 1.83002, value_loss: 99.30906 action_loss: -12.27425\n",
            "update_step:  11 model loss: 38.38532, kl_loss: 7.75651, obs_loss: 28.88928, reward_loss: 1.73953, value_loss: 67.59492 action_loss: -9.87151\n",
            "update_step:  12 model loss: 38.39772, kl_loss: 7.09650, obs_loss: 29.58870, reward_loss: 1.71252, value_loss: 51.21080 action_loss: -8.30780\n",
            "update_step:  13 model loss: 37.63720, kl_loss: 6.63579, obs_loss: 29.38301, reward_loss: 1.61840, value_loss: 36.65556 action_loss: -6.66201\n",
            "update_step:  14 model loss: 37.69115, kl_loss: 6.72662, obs_loss: 29.40779, reward_loss: 1.55674, value_loss: 35.34005 action_loss: -6.45522\n",
            "update_step:  15 model loss: 36.49044, kl_loss: 6.40090, obs_loss: 28.62705, reward_loss: 1.46249, value_loss: 34.84471 action_loss: -6.25635\n",
            "update_step:  16 model loss: 36.01958, kl_loss: 6.36145, obs_loss: 28.23609, reward_loss: 1.42205, value_loss: 38.84455 action_loss: -6.71446\n",
            "update_step:  17 model loss: 35.08394, kl_loss: 6.50987, obs_loss: 27.18993, reward_loss: 1.38415, value_loss: 45.63057 action_loss: -7.67695\n",
            "update_step:  18 model loss: 33.98256, kl_loss: 6.31160, obs_loss: 26.41873, reward_loss: 1.25224, value_loss: 61.53694 action_loss: -9.41550\n",
            "update_step:  19 model loss: 34.11743, kl_loss: 6.75135, obs_loss: 26.06688, reward_loss: 1.29920, value_loss: 64.15436 action_loss: -9.62828\n",
            "update_step:  20 model loss: 33.78939, kl_loss: 6.53957, obs_loss: 26.02090, reward_loss: 1.22892, value_loss: 74.56084 action_loss: -10.66620\n",
            "update_step:  21 model loss: 32.89462, kl_loss: 6.25814, obs_loss: 25.38102, reward_loss: 1.25546, value_loss: 84.93147 action_loss: -11.83136\n",
            "update_step:  22 model loss: 32.89492, kl_loss: 5.92418, obs_loss: 25.65246, reward_loss: 1.31828, value_loss: 79.76124 action_loss: -11.43977\n",
            "update_step:  23 model loss: 32.30120, kl_loss: 5.73192, obs_loss: 25.27485, reward_loss: 1.29443, value_loss: 83.65139 action_loss: -11.96199\n",
            "update_step:  24 model loss: 32.94453, kl_loss: 5.68022, obs_loss: 25.87347, reward_loss: 1.39084, value_loss: 67.94629 action_loss: -10.39036\n",
            "update_step:  25 model loss: 31.57300, kl_loss: 5.32968, obs_loss: 25.07602, reward_loss: 1.16729, value_loss: 80.44428 action_loss: -11.68318\n",
            "update_step:  26 model loss: 31.65110, kl_loss: 5.42755, obs_loss: 24.94073, reward_loss: 1.28282, value_loss: 69.80546 action_loss: -10.85618\n",
            "update_step:  27 model loss: 31.75476, kl_loss: 5.49064, obs_loss: 24.97829, reward_loss: 1.28583, value_loss: 82.70569 action_loss: -11.87998\n",
            "update_step:  28 model loss: 31.67633, kl_loss: 5.51482, obs_loss: 24.89525, reward_loss: 1.26626, value_loss: 77.52605 action_loss: -11.74785\n",
            "update_step:  29 model loss: 30.90260, kl_loss: 5.69028, obs_loss: 23.96824, reward_loss: 1.24409, value_loss: 69.67908 action_loss: -11.21726\n",
            "update_step:  30 model loss: 30.65223, kl_loss: 5.75825, obs_loss: 23.77150, reward_loss: 1.12248, value_loss: 65.11114 action_loss: -11.11506\n",
            "update_step:  31 model loss: 31.66460, kl_loss: 5.89591, obs_loss: 24.53910, reward_loss: 1.22959, value_loss: 52.60862 action_loss: -10.05509\n",
            "update_step:  32 model loss: 31.24243, kl_loss: 5.75364, obs_loss: 24.21617, reward_loss: 1.27262, value_loss: 54.27315 action_loss: -10.40450\n",
            "update_step:  33 model loss: 30.77385, kl_loss: 5.73111, obs_loss: 23.92104, reward_loss: 1.12169, value_loss: 63.59233 action_loss: -11.46806\n",
            "update_step:  34 model loss: 30.93709, kl_loss: 5.60300, obs_loss: 24.11740, reward_loss: 1.21669, value_loss: 68.29940 action_loss: -12.16137\n",
            "update_step:  35 model loss: 30.33265, kl_loss: 5.56662, obs_loss: 23.58451, reward_loss: 1.18153, value_loss: 72.55772 action_loss: -12.75459\n",
            "update_step:  36 model loss: 31.08992, kl_loss: 5.39633, obs_loss: 24.45625, reward_loss: 1.23733, value_loss: 64.06907 action_loss: -12.22559\n",
            "update_step:  37 model loss: 30.31608, kl_loss: 5.38553, obs_loss: 23.78065, reward_loss: 1.14990, value_loss: 62.37965 action_loss: -12.18798\n",
            "update_step:  38 model loss: 29.89913, kl_loss: 5.32522, obs_loss: 23.32521, reward_loss: 1.24870, value_loss: 54.70736 action_loss: -11.60256\n",
            "update_step:  39 model loss: 30.14407, kl_loss: 5.36118, obs_loss: 23.59713, reward_loss: 1.18576, value_loss: 58.31052 action_loss: -12.26939\n",
            "update_step:  40 model loss: 31.13359, kl_loss: 5.35042, obs_loss: 24.41296, reward_loss: 1.37021, value_loss: 57.37161 action_loss: -12.50920\n",
            "update_step:  41 model loss: 30.21468, kl_loss: 5.35656, obs_loss: 23.68877, reward_loss: 1.16935, value_loss: 63.18470 action_loss: -13.44637\n",
            "update_step:  42 model loss: 29.61679, kl_loss: 5.43689, obs_loss: 23.00512, reward_loss: 1.17478, value_loss: 61.88635 action_loss: -13.51801\n",
            "update_step:  43 model loss: 29.57881, kl_loss: 5.48256, obs_loss: 22.96561, reward_loss: 1.13064, value_loss: 63.37989 action_loss: -13.90886\n",
            "update_step:  44 model loss: 30.46894, kl_loss: 5.66930, obs_loss: 23.66880, reward_loss: 1.13084, value_loss: 70.54996 action_loss: -14.94324\n",
            "update_step:  45 model loss: 29.55795, kl_loss: 5.47252, obs_loss: 22.92081, reward_loss: 1.16462, value_loss: 61.34375 action_loss: -14.32867\n",
            "update_step:  46 model loss: 29.90547, kl_loss: 5.37712, obs_loss: 23.37841, reward_loss: 1.14994, value_loss: 61.54092 action_loss: -14.72314\n",
            "update_step:  47 model loss: 28.26743, kl_loss: 5.13870, obs_loss: 21.99520, reward_loss: 1.13353, value_loss: 51.73978 action_loss: -14.15953\n",
            "update_step:  48 model loss: 28.02623, kl_loss: 5.10975, obs_loss: 21.89944, reward_loss: 1.01704, value_loss: 49.97275 action_loss: -14.60404\n",
            "update_step:  49 model loss: 29.43789, kl_loss: 5.21479, obs_loss: 23.03877, reward_loss: 1.18433, value_loss: 52.25089 action_loss: -15.27139\n",
            "update_step:  50 model loss: 29.74501, kl_loss: 5.42550, obs_loss: 23.16317, reward_loss: 1.15634, value_loss: 51.74799 action_loss: -15.59906\n",
            "update_step:  51 model loss: 29.48905, kl_loss: 5.40883, obs_loss: 22.93346, reward_loss: 1.14676, value_loss: 48.26589 action_loss: -15.22126\n",
            "update_step:  52 model loss: 28.87824, kl_loss: 5.16379, obs_loss: 22.66422, reward_loss: 1.05023, value_loss: 55.59332 action_loss: -16.50938\n",
            "update_step:  53 model loss: 29.72295, kl_loss: 5.38711, obs_loss: 23.12978, reward_loss: 1.20607, value_loss: 46.72204 action_loss: -15.79382\n",
            "update_step:  54 model loss: 29.13382, kl_loss: 5.41613, obs_loss: 22.62029, reward_loss: 1.09740, value_loss: 44.15990 action_loss: -16.38882\n",
            "update_step:  55 model loss: 29.18660, kl_loss: 5.36986, obs_loss: 22.68342, reward_loss: 1.13331, value_loss: 39.69389 action_loss: -16.34569\n",
            "update_step:  56 model loss: 28.03170, kl_loss: 5.17819, obs_loss: 21.81715, reward_loss: 1.03636, value_loss: 34.96826 action_loss: -16.11546\n",
            "update_step:  57 model loss: 28.66528, kl_loss: 5.20700, obs_loss: 22.36097, reward_loss: 1.09731, value_loss: 33.98029 action_loss: -16.29235\n",
            "update_step:  58 model loss: 29.08129, kl_loss: 5.25890, obs_loss: 22.73885, reward_loss: 1.08354, value_loss: 34.82473 action_loss: -16.79190\n",
            "update_step:  59 model loss: 27.85635, kl_loss: 5.00683, obs_loss: 21.75238, reward_loss: 1.09714, value_loss: 32.95287 action_loss: -16.65886\n",
            "update_step:  60 model loss: 27.49332, kl_loss: 5.05146, obs_loss: 21.41165, reward_loss: 1.03022, value_loss: 39.35366 action_loss: -18.29981\n",
            "update_step:  61 model loss: 28.82884, kl_loss: 5.20708, obs_loss: 22.50221, reward_loss: 1.11954, value_loss: 39.55685 action_loss: -18.87296\n",
            "update_step:  62 model loss: 28.45255, kl_loss: 5.30376, obs_loss: 22.09669, reward_loss: 1.05210, value_loss: 29.89076 action_loss: -17.70247\n",
            "update_step:  63 model loss: 27.63550, kl_loss: 5.09842, obs_loss: 21.53010, reward_loss: 1.00698, value_loss: 29.23129 action_loss: -18.36018\n",
            "update_step:  64 model loss: 28.69503, kl_loss: 5.19906, obs_loss: 22.33718, reward_loss: 1.15879, value_loss: 25.11959 action_loss: -18.13620\n",
            "update_step:  65 model loss: 27.98009, kl_loss: 5.09286, obs_loss: 21.83285, reward_loss: 1.05439, value_loss: 26.75917 action_loss: -19.21435\n",
            "update_step:  66 model loss: 27.29257, kl_loss: 4.99420, obs_loss: 21.34428, reward_loss: 0.95410, value_loss: 28.85752 action_loss: -20.02478\n",
            "update_step:  67 model loss: 28.38430, kl_loss: 5.10891, obs_loss: 22.11270, reward_loss: 1.16269, value_loss: 29.24092 action_loss: -20.33073\n",
            "update_step:  68 model loss: 28.26651, kl_loss: 5.11105, obs_loss: 22.11379, reward_loss: 1.04167, value_loss: 27.92206 action_loss: -21.19436\n",
            "update_step:  69 model loss: 27.97722, kl_loss: 5.14666, obs_loss: 21.89224, reward_loss: 0.93832, value_loss: 27.99340 action_loss: -21.78705\n",
            "update_step:  70 model loss: 27.08284, kl_loss: 5.09668, obs_loss: 21.01521, reward_loss: 0.97095, value_loss: 22.90788 action_loss: -20.82869\n",
            "update_step:  71 model loss: 27.35199, kl_loss: 5.06260, obs_loss: 21.29323, reward_loss: 0.99616, value_loss: 21.92691 action_loss: -21.43580\n",
            "update_step:  72 model loss: 27.91389, kl_loss: 4.95064, obs_loss: 21.96646, reward_loss: 0.99678, value_loss: 23.48910 action_loss: -22.47432\n",
            "update_step:  73 model loss: 27.31202, kl_loss: 4.97321, obs_loss: 21.35313, reward_loss: 0.98568, value_loss: 22.64127 action_loss: -22.96745\n",
            "update_step:  74 model loss: 27.79828, kl_loss: 4.98350, obs_loss: 21.78191, reward_loss: 1.03286, value_loss: 24.13375 action_loss: -24.08514\n",
            "update_step:  75 model loss: 27.65715, kl_loss: 5.03816, obs_loss: 21.67332, reward_loss: 0.94567, value_loss: 20.46334 action_loss: -23.83079\n",
            "update_step:  76 model loss: 27.51138, kl_loss: 4.98176, obs_loss: 21.57009, reward_loss: 0.95954, value_loss: 14.88608 action_loss: -22.84526\n",
            "update_step:  77 model loss: 27.81423, kl_loss: 5.10433, obs_loss: 21.77862, reward_loss: 0.93128, value_loss: 12.87977 action_loss: -23.09255\n",
            "update_step:  78 model loss: 27.50890, kl_loss: 5.08742, obs_loss: 21.51070, reward_loss: 0.91078, value_loss: 11.69257 action_loss: -23.46518\n",
            "update_step:  79 model loss: 28.08743, kl_loss: 5.17916, obs_loss: 21.89381, reward_loss: 1.01446, value_loss: 9.90264 action_loss: -22.79800\n",
            "update_step:  80 model loss: 28.35871, kl_loss: 5.04706, obs_loss: 22.21768, reward_loss: 1.09397, value_loss: 11.53653 action_loss: -24.29923\n",
            "update_step:  81 model loss: 27.67742, kl_loss: 5.08668, obs_loss: 21.69441, reward_loss: 0.89633, value_loss: 13.19844 action_loss: -25.73635\n",
            "update_step:  82 model loss: 27.93208, kl_loss: 5.03945, obs_loss: 21.77298, reward_loss: 1.11964, value_loss: 12.09471 action_loss: -25.50947\n",
            "update_step:  83 model loss: 28.06484, kl_loss: 5.05559, obs_loss: 21.99352, reward_loss: 1.01573, value_loss: 10.63313 action_loss: -26.09529\n",
            "update_step:  84 model loss: 27.60921, kl_loss: 5.02211, obs_loss: 21.58896, reward_loss: 0.99814, value_loss: 9.77913 action_loss: -26.09264\n",
            "update_step:  85 model loss: 27.43012, kl_loss: 4.95164, obs_loss: 21.45419, reward_loss: 1.02429, value_loss: 9.67994 action_loss: -25.81804\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-62bcaac8a013>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobs_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreward_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mmodel_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for episode in range(seed_episodes, all_episodes):\n",
        "    # -----------------------------\n",
        "    #      経験を集める\n",
        "    # -----------------------------\n",
        "    start = time.time()\n",
        "    # 行動を決定するためのエージェントを宣言\n",
        "    policy = Agent(encoder, rssm.transition, action_model)\n",
        "\n",
        "    env = make_env()\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = policy(obs)\n",
        "        # 探索のためにガウス分布に従うノイズを加える(explaration noise)\n",
        "        action += np.random.normal(0, np.sqrt(action_noise_var),\n",
        "                                     env.action_space.shape[0])\n",
        "        next_obs, reward, done, _ = env.step(action)\n",
        "\n",
        "        #リプレイバッファに観測，行動，報酬，doneを格納\n",
        "        replay_buffer.push(obs, action, reward, done)\n",
        "\n",
        "        obs = next_obs\n",
        "        total_reward += reward\n",
        "\n",
        "    # 訓練時の報酬と経過時間をログとして表示\n",
        "    writer.add_scalar('total reward at train', total_reward, episode)\n",
        "    print('episode [%4d/%4d] is collected. Total reward is %f' %\n",
        "            (episode+1, all_episodes, total_reward))\n",
        "    print('elasped time for interaction: %.2fs' % (time.time() - start))\n",
        "\n",
        "    # NNのパラメータを更新する\n",
        "    start = time.time()\n",
        "    for update_step in range(collect_interval):\n",
        "        # -------------------------------------------------------------------------------------\n",
        "        #  RSSM(trainsition_model, obs_model, reward_model)の更新 - Dynamics learning\n",
        "        # -------------------------------------------------------------------------------------\n",
        "        observations, actions, rewards, _ = \\\n",
        "            replay_buffer.sample(batch_size, chunk_length)\n",
        "\n",
        "        # 観測を前処理し，RNNを用いたPyTorchでの学習のためにTensorの次元を調整\n",
        "        observations = preprocess_obs(observations)\n",
        "        observations = torch.as_tensor(observations, device=device)\n",
        "        observations = observations.transpose(3, 4).transpose(2, 3)\n",
        "        observations = observations.transpose(0, 1)\n",
        "        actions = torch.as_tensor(actions, device=device).transpose(0, 1)\n",
        "        rewards = torch.as_tensor(rewards, device=device).transpose(0, 1)\n",
        "\n",
        "        # 観測をエンコーダで低次元のベクトルに変換\n",
        "        embedded_observations = encoder(\n",
        "            observations.reshape(-1, 3, 64, 64)).view(chunk_length, batch_size, -1)\n",
        "\n",
        "        # 低次元の状態表現を保持しておくためのTensorを定義\n",
        "        states = torch.zeros(chunk_length, batch_size, state_dim, device=device)\n",
        "        rnn_hiddens = torch.zeros(chunk_length, batch_size, rnn_hidden_dim, device=device)\n",
        "\n",
        "        # 低次元の状態表現は最初はゼロ初期化（timestep１つ分）\n",
        "        state = torch.zeros(batch_size, state_dim, device=device)\n",
        "        rnn_hidden = torch.zeros(batch_size, rnn_hidden_dim, device=device)\n",
        "\n",
        "        # 状態s_tの予測を行ってそのロスを計算する（priorとposteriorの間のKLダイバージェンス）\n",
        "        kl_loss = 0\n",
        "        for l in range(chunk_length-1):\n",
        "            next_state_prior, next_state_posterior, rnn_hidden = \\\n",
        "                rssm.transition(state, actions[l], rnn_hidden, embedded_observations[l+1])\n",
        "            state = next_state_posterior.rsample()\n",
        "            states[l+1] = state\n",
        "            rnn_hiddens[l+1] = rnn_hidden\n",
        "            kl = kl_divergence(next_state_prior, next_state_posterior).sum(dim=1) # WRITE ME （ヒント: kl_divergence()を使用）\n",
        "            kl_loss += kl.clamp(min=free_nats).mean()  # 原論文通り，KL誤差がfree_nats以下の時は無視\n",
        "        kl_loss /= (chunk_length - 1)\n",
        "\n",
        "        # states[0] and rnn_hiddens[0]はゼロ初期化なので以降では使わない\n",
        "        # states，rnn_hiddensは低次元の状態表現\n",
        "        states = states[1:]\n",
        "        rnn_hiddens = rnn_hiddens[1:]\n",
        "\n",
        "        # 観測を再構成，また，報酬を予測\n",
        "        flatten_states = states.view(-1, state_dim)\n",
        "        flatten_rnn_hiddens = rnn_hiddens.view(-1, rnn_hidden_dim)\n",
        "        recon_observations = rssm.observation(flatten_states, flatten_rnn_hiddens).view(chunk_length-1, batch_size, 3, 64, 64)\n",
        "        predicted_rewards = rssm.reward(flatten_states, flatten_rnn_hiddens).view(chunk_length-1, batch_size, 1)\n",
        "\n",
        "        # 観測と報酬の予測誤差を計算\n",
        "        obs_loss = 0.5 * F.mse_loss(recon_observations, observations[1:], reduction='none').mean([0, 1]).sum()\n",
        "        reward_loss = 0.5 * F.mse_loss(predicted_rewards, rewards[:-1])\n",
        "\n",
        "        # 以上のロスを合わせて勾配降下で更新する\n",
        "        model_loss = kl_loss + obs_loss + reward_loss\n",
        "        model_optimizer.zero_grad()\n",
        "        model_loss.backward()\n",
        "        clip_grad_norm_(model_params, clip_grad_norm)\n",
        "        model_optimizer.step()\n",
        "\n",
        "        # --------------------------------------------------\n",
        "        #  Action Model, Value　Modelの更新　- Behavior learning\n",
        "        # --------------------------------------------------\n",
        "        # Actor-Criticのロスで他のモデルを更新することはないので勾配の流れを一度遮断\n",
        "        # flatten_states, flatten_rnn_hiddensは RSSMから得られた低次元の状態表現を平坦化した値\n",
        "        flatten_states = flatten_states.detach()\n",
        "        flatten_rnn_hiddens = flatten_rnn_hiddens.detach()\n",
        "\n",
        "        # DreamerにおけるActor-Criticの更新のために，現在のモデルを用いた\n",
        "        # 数ステップ先の未来の状態予測を保持するためのTensorを用意\n",
        "        imagined_states = torch.zeros(imagination_horizon + 1,\n",
        "                                         *flatten_states.shape,\n",
        "                                          device=flatten_states.device)\n",
        "        imagined_rnn_hiddens = torch.zeros(imagination_horizon + 1,\n",
        "                                                *flatten_rnn_hiddens.shape,\n",
        "                                                device=flatten_rnn_hiddens.device)\n",
        "\n",
        "        #　未来予測をして想像上の軌道を作る前に，最初の状態としては先ほどモデルの更新で使っていた\n",
        "        # リプレイバッファからサンプルされた観測データを取り込んだ上で推論した状態表現を使う\n",
        "        imagined_states[0] = flatten_states\n",
        "        imagined_rnn_hiddens[0] = flatten_rnn_hiddens\n",
        "\n",
        "        # open-loopで未来の状態予測を使い，想像上の軌道を作る\n",
        "        for h in range(1, imagination_horizon + 1):\n",
        "            # 行動はActionModelで決定．この行動はモデルのパラメータに対して微分可能で,\n",
        "            #　これを介してActionModelは更新される\n",
        "            actions = action_model(flatten_states, flatten_rnn_hiddens)\n",
        "            flatten_states_prior, flatten_rnn_hiddens = rssm.transition.prior(rssm.transition.recurrent(flatten_states,\n",
        "                                                                   actions,\n",
        "                                                                   flatten_rnn_hiddens))\n",
        "            flatten_states = flatten_states_prior.rsample()\n",
        "            imagined_states[h] = flatten_states\n",
        "            imagined_rnn_hiddens[h] = flatten_rnn_hiddens\n",
        "\n",
        "        # RSSMのreward_modelにより予測された架空の軌道に対する報酬を計算\n",
        "        flatten_imagined_states = imagined_states.view(-1, state_dim)\n",
        "        flatten_imagined_rnn_hiddens = imagined_rnn_hiddens.view(-1, rnn_hidden_dim)\n",
        "        imagined_rewards = \\\n",
        "            rssm.reward(flatten_imagined_states,\n",
        "                        flatten_imagined_rnn_hiddens).view(imagination_horizon + 1, -1)\n",
        "        imagined_values = \\\n",
        "            value_model(flatten_imagined_states,\n",
        "                        flatten_imagined_rnn_hiddens).view(imagination_horizon + 1, -1)\n",
        "\n",
        "        # λ-returnのターゲットを計算(V_{\\lambda}(s_{\\tau})\n",
        "        lambda_target_values = lambda_target(imagined_rewards, imagined_values, gamma, lambda_) # WRITE ME （ヒント: lambda_target()を利用）\n",
        "\n",
        "        # 価値関数の予測した価値が大きくなるようにActionModelを更新\n",
        "        # PyTorchの基本は勾配降下だが，今回は大きくしたいので-1をかける\n",
        "        action_loss = -lambda_target_values.mean()\n",
        "        action_optimizer.zero_grad()\n",
        "        action_loss.backward()\n",
        "        clip_grad_norm_(action_model.parameters(), clip_grad_norm)\n",
        "        action_optimizer.step()\n",
        "\n",
        "        # TD(λ)ベースの目的関数で価値関数を更新（価値関数のみを学習するため，学習しない変数のグラフは切っている．)\n",
        "        imagined_values = value_model(flatten_imagined_states.detach(), flatten_imagined_rnn_hiddens.detach()).view(imagination_horizon + 1, -1)\n",
        "        value_loss = 0.5 * F.mse_loss(imagined_values, lambda_target_values.detach()) # WRITE ME （ヒント: 0.5 * F.mse_loss()を使用）\n",
        "        value_optimizer.zero_grad()\n",
        "        value_loss.backward()\n",
        "        clip_grad_norm_(value_model.parameters(), clip_grad_norm)\n",
        "        value_optimizer.step()\n",
        "\n",
        "        # ログをTensorBoardに出力\n",
        "        print('update_step: %3d model loss: %.5f, kl_loss: %.5f, '\n",
        "             'obs_loss: %.5f, reward_loss: %.5f, '\n",
        "             'value_loss: %.5f action_loss: %.5f'\n",
        "                % (update_step + 1, model_loss.item(), kl_loss.item(),\n",
        "                    obs_loss.item(), reward_loss.item(),\n",
        "                    value_loss.item(), action_loss.item()))\n",
        "        total_update_step = episode * collect_interval + update_step\n",
        "        writer.add_scalar('model loss', model_loss.item(), total_update_step)\n",
        "        writer.add_scalar('kl loss', kl_loss.item(), total_update_step)\n",
        "        writer.add_scalar('obs loss', obs_loss.item(), total_update_step)\n",
        "        writer.add_scalar('reward loss', reward_loss.item(), total_update_step)\n",
        "        writer.add_scalar('value loss', value_loss.item(), total_update_step)\n",
        "        writer.add_scalar('action loss', action_loss.item(), total_update_step)\n",
        "\n",
        "    print('elasped time for update: %.2fs' % (time.time() - start))\n",
        "\n",
        "    # --------------------------------------------------------------\n",
        "    #    テストフェーズ．探索ノイズなしでの性能を評価する\n",
        "    # --------------------------------------------------------------\n",
        "    if (episode + 1) % test_interval == 0:\n",
        "        policy = Agent(encoder, rssm.transition, action_model)\n",
        "        start = time.time()\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            action = policy(obs, training=False)\n",
        "            obs, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "\n",
        "        writer.add_scalar('total reward at test', total_reward, episode)\n",
        "        print('Total test reward at episode [%4d/%4d] is %f' %\n",
        "                (episode+1, all_episodes, total_reward))\n",
        "        print('elasped time for test: %.2fs' % (time.time() - start))\n",
        "\n",
        "    if (episode + 1) % model_save_interval == 0:\n",
        "        # 定期的に学習済みモデルのパラメータを保存する\n",
        "        model_log_dir = os.path.join(log_dir, 'episode_%04d' % (episode + 1))\n",
        "        os.makedirs(model_log_dir)\n",
        "        torch.save(encoder.state_dict(), os.path.join(model_log_dir, 'encoder.pth'))\n",
        "        torch.save(rssm.transition.state_dict(), os.path.join(model_log_dir, 'rssm.pth'))\n",
        "        torch.save(rssm.observation.state_dict(), os.path.join(model_log_dir, 'obs_model.pth'))\n",
        "        torch.save(rssm.reward.state_dict(), os.path.join(model_log_dir, 'reward_model.pth'))\n",
        "        torch.save(value_model.state_dict(), os.path.join(model_log_dir, 'value_model.pth'))\n",
        "        torch.save(action_model.state_dict(), os.path.join(model_log_dir, 'action_model.pth'))\n",
        "    del env\n",
        "    gc.collect()\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFMZzNPU_B-l"
      },
      "source": [
        "TensorBoardで学習結果を確認してみます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTJL-DXo-omv"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir='./logs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3F2tAU0kepm"
      },
      "source": [
        "##  10.結果の確認\n",
        "保存された学習済み重みを用いて，動作を確認してみましょう."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnfmCGFFAV0q"
      },
      "source": [
        "学習にはかなりの時間がかかるので，ここでは事前に学習しておいた重みを読み込むことにします．時間のある方は，上記のコードで実際に学習した重みを使って同様に試してみてください."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PGif3TtyilSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b1281b-f5c2-4526-ed24-9c31451a3951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 15l6-EsNMD0Xn95x_278-ZnQ30GtmCaAx into ./episode_0100.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ],
      "source": [
        "# 事前にGoogle Driveにあげておいた学習済み重みをダウンロードします\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "file_id = \"15l6-EsNMD0Xn95x_278-ZnQ30GtmCaAx\"  # Google Driveにあげた学習済重みのfile idを取得してここにコピペしてください\n",
        "gdd.download_file_from_google_drive(\n",
        "    file_id=file_id, dest_path=\"./episode_0100.zip\", unzip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hKYF5zP6ALD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae108d6-00a9-4662-ae2a-ad69e0e421b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "encoder.load_state_dict(torch.load(\"./episode_0100/encoder.pth\"))\n",
        "rssm.transition.load_state_dict(torch.load(\"./episode_0100/rssm.pth\"))\n",
        "rssm.observation.load_state_dict(torch.load(\"./episode_0100/obs_model.pth\"))\n",
        "action_model.load_state_dict(torch.load(\"./episode_0100/action_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MSt_P-WdEnmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "622ad059-43b6-412c-ffb6-f5b55823d279"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a6c2a9114db2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習済み重みを用いず，このcolab上で学習したモデルを使うなら，このセルを実行してください．\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# あるいは，定期的に保存されているモデルを読み込むこともできます\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoder.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rssm.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m rssm.observation.load_state_dict(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_log_dir' is not defined"
          ]
        }
      ],
      "source": [
        "# 学習済み重みを用いず，このcolab上で学習したモデルを使うなら，このセルを実行してください．\n",
        "# あるいは，定期的に保存されているモデルを読み込むこともできます\n",
        "encoder.load_state_dict(torch.load(os.path.join(model_log_dir, \"encoder.pth\")))\n",
        "rssm.transition.load_state_dict(torch.load(os.path.join(model_log_dir, \"rssm.pth\")))\n",
        "rssm.observation.load_state_dict(\n",
        "    torch.load(os.path.join(model_log_dir, \"obs_model.pth\"))\n",
        ")\n",
        "action_model.load_state_dict(\n",
        "    torch.load(os.path.join(model_log_dir, \"action_model.pth\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fCAGLBjGaDz"
      },
      "source": [
        "動作の様子を動画で観てみることにします．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phTlvvC8GZdU"
      },
      "outputs": [],
      "source": [
        "# 結果を動画で観てみるための関数\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "from matplotlib import animation\n",
        "\n",
        "\n",
        "def display_video(frames: List[np.ndarray]) -> None:\n",
        "    \"\"\"\n",
        "    結果を動画にするための関数．\n",
        "\n",
        "    frames : List[np.ndarray]\n",
        "        観測画像をリスト化したもの．\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 8), dpi=50)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "        plt.title(\"Step %d\" % (i))\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=50)\n",
        "    display(HTML(anim.to_jshtml(default_mode=\"once\")))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tsrk0bfEXpO"
      },
      "outputs": [],
      "source": [
        "env = make_env()\n",
        "policy = Agent(encoder, rssm.transition, action_model)\n",
        "obs = env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "frames = [obs]\n",
        "while not done:\n",
        "    action = policy(obs, training=False)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    frames.append(obs)\n",
        "\n",
        "print(\"Total Reward:\", total_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN-6pLFxG6sz"
      },
      "outputs": [],
      "source": [
        "display_video(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62nJ7xoek-RU"
      },
      "source": [
        "ある時点の適当な観測から，世界モデルで**open-loop**に未来予測を行わせ，観測を再構成して視覚的に観てみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUYvdbwSlDo_"
      },
      "outputs": [],
      "source": [
        "policy = Agent(encoder, rssm.transition, action_model)\n",
        "obs = env.reset()\n",
        "# 最初に適当な回数行動します．この間にrnn_hiddenに観測の系列に関する情報が蓄積されます\n",
        "for _ in range(np.random.randint(5, 100)):\n",
        "    action = policy(obs, training=False)\n",
        "    obs, _, _, _ = env.step(action)\n",
        "\n",
        "# 現在の観測をベクトルに変換し，それを元にposteriorを計算します．\n",
        "preprocessed_obs = preprocess_obs(obs)\n",
        "preprocessed_obs = torch.as_tensor(preprocessed_obs, device=device)\n",
        "preprocessed_obs = preprocessed_obs.transpose(1, 2).transpose(0, 1).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    embedded_obs = encoder(preprocessed_obs)\n",
        "\n",
        "# posteriorからのサンプルとして得られたstateと，policyから取得したrnn_hiddenが低次元の状態表現です．\n",
        "# open-loopの予測なので，これ以降この2つの変数は状態遷移を表すpriorでしか更新しません．\n",
        "# （policyの中では，行動を決定するために観測をリアルタイムで反映してposteriorで更新しています）\n",
        "rnn_hidden = policy.rnn_hidden\n",
        "state = rssm.transition.posterior(rnn_hidden, embedded_obs).sample()\n",
        "frame = np.zeros((64, 128, 3))\n",
        "frames = []\n",
        "\n",
        "prediction_length = 100\n",
        "for _ in range(prediction_length):\n",
        "    action = policy(obs)\n",
        "    obs, _, _, _ = env.step(action)\n",
        "\n",
        "    action = torch.as_tensor(action, device=device).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        state_prior, rnn_hidden = rssm.transition.prior(\n",
        "            rssm.transition.recurrent(state, action, rnn_hidden)\n",
        "        )\n",
        "        state = state_prior.sample()\n",
        "        predicted_obs = rssm.observation(\n",
        "            state, rnn_hidden\n",
        "        )  # obs_model(state, rnn_hidden)\n",
        "\n",
        "    frame[:, :64, :] = preprocess_obs(obs)\n",
        "    frame[:, 64:, :] = (\n",
        "        predicted_obs.squeeze().transpose(0, 1).transpose(1, 2).cpu().numpy()\n",
        "    )\n",
        "    frames.append((frame + 0.5).clip(0.0, 1.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeH7vX0zLS-P"
      },
      "source": [
        "open-loopの動画予測の結果を，左側に真のフレーム，右側に予測されたフレームと並べてみてみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG9EWSvrDFJ0"
      },
      "outputs": [],
      "source": [
        "display_video(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K0slk_dLPVJ"
      },
      "source": [
        "以上で演習は終わりです．お疲れ様でした！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_PCEOJ69prx"
      },
      "source": [
        "## 11.参考文献\n",
        "[[1]](https://arxiv.org/pdf/1811.04551.pdf) Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, \"Learning Latent Dynamics for Planning from Pixels\", arXiv, 2019\n",
        "\n",
        "[[2]](https://arxiv.org/abs/1912.01603) Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi,\n",
        "\"Dream to Control: Learning Behaviors by Latent Imagination\", ICLR2020"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "1c906a337007ca492b40f9e66323e61f3dcaf71886120485625fb02da1be1aa9"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}